# Action 
random_action : false
hidden_dim: &hidden_dim 10
discount_factor : 0.99
buffer_len : 5000
batch_size : 32
len_history : 5
device : "cuda:0"

# Training Config
env : cartpole
n_envs : 1
timesteps : 1e5
train_start_timestep : 1e3
target_update_freq : 1e3
learning_rate : 1e-4
lr_decay : 0.90
lr_decay_freq : 2000
weight_decay : 0
horizon : 200

# Exploration
epsilon_init : 0.9
epsilon_final : 0.1
epsilon_max_timesteps : 1e5

# Utils
log_freq : 100
checkpoint_num : 10

# Test 
eval_freq : 10000
test_epsilon : 0.0
test_horizon : 200
test_episodes : 32

# --- Network Candidates ----
act: &act Tanh
q: &q
  - [Linear, auto, *hidden_dim, {}]
  - *act
  - [Linear, *hidden_dim, *hidden_dim, {}]
  - *act
  - [Linear, *hidden_dim, auto, {}]
encoder: &encoder
  - [Linear, auto, *hidden_dim, {}]
osi: &osi
  - [Linear, *hidden_dim, *hidden_dim, {}]
  - *act
  - [GRU, *hidden_dim, *hidden_dim, {batch_first: true}]
  - *act
  - [Linear, *hidden_dim, auto, {}]

# --- Models ---
q_net: *q
OSI: *osi
state_encoder: *encoder
action_encoder: *encoder